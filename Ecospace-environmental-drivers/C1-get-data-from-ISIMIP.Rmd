---
title: "Accessing data from ISIMIP repository"
author: "Denisse Fierro Arcos"
date: "2023-08-19"
output: 
  github_document:
    toc: true
    html_preview: false
---

# Introduction
This notebook will accessing data from the [Inter-Sectoral Impact Model Intercomparison Project (ISIMIP) Repository](https://data.isimip.org/). There are various datasets available, but as example we will be accessing Input Data > Climate Forcing > ISIMIP3a simulation round. We will use the sea surface temperature (`tos`) monthly global output from the GFDL-MOM6-COBALT2 model.  

In this notebook, we will use `Python` to make use of some functions from the `isimip-client` library, which you should have already installed in your local machine if you followed the instructions in the `README` file. If you have not done this yet, make sure you follow these instructions before running this notebook.  
  
After we have downloaded the data we need with the `isimip-client` library, we will then move to `R` to visualise the data.

## Loading R libraries
All libraries used in this notebook should already be installed in your local machine. Make sure you follow the instructions in the `README` file before running this notebook.  

```{r results = "hide", warnings = F, message = F}
rm(list=ls());rm(.SavedPlots)
library(reticulate)
library(tidyverse)
library(metR)
library(lubridate)
library(raster)
library(sf)
library(ncdf4)
```

## Using Python in an R notebook
We will use the `reticulate` package to call `Python` in this notebook. Before you run this, make sure you have edited the `.Rprofile` file following the instructions in the README.  

```{r warnings = F, message = F}
#Calling a specific conda environment
use_condaenv("fishmip", conda = "C:/Users/User/miniconda3/envs/fishmip")
use_condaenv("fishmip") 
```
## Loading ISIMIP Client script
Call the `isimip-client` library and load it into R 
  
```{r}
#Loading isimip-client into R
cl <- import("isimip_client.client")
```

```{python}
#Loading the library
import isimip_client.client as cl

#Starting a session
client = cl.ISIMIPClient()
```

## Starting an `isimip-client` session
Start a session to query the ISIMIP database. We will look for climate data (considered as Input Data) from the ISIMIP3a simulation. 
  
Parameters available in the ISIMIP Repository website: [here](https://data.isimip.org/datasets/d7aca05a-27de-440e-a5b2-2c21ba831bcd/). The climate variable parameters used here can be seen under `Specifiers`. 

Climate variables that can be specified include the following:
 - chl: Chlorophyll concentration
 - expc-bot: Export production at the bottom
 - intpoc: Integrated particulate organic carbon
 - intpp, intppdiat, intppdiaz, intpppico: Integrated primary production (total, diatoms, diazotrophs, picophytoplankton)
 - o2, o2-bot, o2-surf: Oxygen concentration (general, at the bottom, at the surface)
 - ph, ph-bot, ph-surf: pH level (general, at the bottom, at the surface)
 - phyc, phyc-vint, phydiat, phydiat-vint, phydiaz, phydiaz-vint, phypico, phypico-vint: Phytoplankton concentration (various types and vertical integrals)
 - siconc: Sea ice concentration
 - so, so-bot, so-surf: Salinity (general, at the bottom, at the surface)
 - thetao: Potential temperature of sea water
 - thkcello: Ocean model layer thickness
 - tob: Temperature at the bottom
 - tos: Temperature at the surface
 - uo, vo: Zonal (east-west) and meridional (north-south) ocean velocities
 - zmeso, zmeso-vint, zmicro, zmicro-vint, zooc, zooc-vint: Different groups/types of zooplankton and their vertical integrals.

```{python}
## Set list of specifiers to query ISIMIP database
clim_var = ['chl', 'tos', 'tob', 'phyc', 'so', 'o2', 'ph', 'zooc', 'intpp']
query_list = []  # Initialize an empty list to store the queries

for var in clim_var:
    query = client.datasets(simulation_round='ISIMIP3a',
                            product='InputData',
                            category='climate',
                            climate_forcing='gfdl-mom6-cobalt2',
                            climate_scenario='obsclim',
                            subcategory='ocean',
                            region='global',
                            time_step='monthly',
                            resolution='15arcmin',
                            climate_variable=var)
    query_list.append(query)  # Append each query to the list

## Check the number of results we obtained from our query. Queries with >1 result are stored as a list. 
for query in query_list: 
    query['results'][0]['specifiers']['climate_variable']
    query['count']

```

Extract URLs to download the data from our queries
```{python}
## Empty lists to save URLs linking to files
urls = []
urls_sub = []

## Loop through each entry available in search results
for query in query_list: 
  for datasets in query['results']:
    for paths in datasets['files']:
      urls.append(paths['file_url'])
      urls_sub.append(paths['path'])
      

## Check URLs
len(urls)
for url in urls:
    print(url)  

```

## Set to spatial extent of GOM
The files in the search results include data for the entire planet as the earth system models are global in extent.

Check bounding box from Ecospace depth/base map
```{r} 
library(rgdal)
region_asc <- raster::raster("C:/Users/User/OneDrive - University of Florida/Research/24 Gulfwide EwE/FishMIP_Model_Data/data/shorelinecorrected-basemap-depth-131x53-08 min-14sqkm.asc")
region_shp <- rasterToPolygons(region_asc, fun = function(x) {x > 0}, dissolve = TRUE)
region_bbox <- st_bbox(region_shp)

bbox_GOM <- c(region_bbox$ymin, region_bbox$ymax, region_bbox$xmin, region_bbox$xmax)
print(bbox_GOM)
```

## Set bounding box for the data downloads
```{python}
GOM_data_URL = client.cutout(urls_sub, bbox = [24., 31., -98., -80.5]) #Use the cutout function to create a bounding box for our dataset
print(GOM_data_URL)
```

## Downloading data to disk
We will download the data and store it into the `MOM6/data_downloads/` folder. First we will make sure a folder exists and if it does not exist, we will create one.

```{python}
#Importing library to check if folder exists
import os

#Creating a data folder if one does not already exist
if os.path.exists('../MOM6/data_downloads/') == False:
  os.makedirs('../MOM6/data_downloads/')
else:
  print('Folder already exists')

```

## Download from ISIMAP
Use the `client.download()` function to save data to disk. 

```{python eval = F}
#To download the subsetted data
client.download(url = GOM_data_URL['file_url'], \
                path = '../MOM6/data_downloads/', validate = False, \
                extract = True)

```
  
## Inspect contents of netcdf files

```{r}
#Provide file path to netcdf that was recently downloaded.
data_file <- list.files(path = '../MOM6/data_downloads/', pattern = "nc$", full.names = T)
num_vars = length(data_file)

library(ncdf4)

#Check contents of netcdf
for (i in 1:num_vars){
  glance = GlanceNetCDF(data_file[i])
  if (i == 1) print (glance$dims) ## These are the same for all of the variables
  print(glance$vars)
}
```

## Check plots
```{r}
for (i in 1:num_vars){
  xx <- brick(data_file[i], level = 1)
  title <- attributes(xx)$title
  plot(xx[[1]], main = title)
}


```




